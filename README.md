
### Python爬虫集合
> 本仓库是自己编写Python网络爬虫的代码集合

          
1. 『[当当爬虫](./DangDangCrawler)』

- 详细用法可以阅读《 [爬虫实战一：爬取当当网所有 Python 书籍](https://mp.weixin.qq.com/s/_IKBJEkh9HtNhpJEbwsD6Q)》
- 抓取以 Python 为关键字搜索出来的书籍，并保存到 csv 文件中。
- 该项目是 **urllib**、**re**、**BeautifulSoup** 这三个库的用法的实战篇

2.『 [网易云音乐精彩评论爬虫](./NeteaseMusic)』

- 详细用法可以阅读《 [爬取网易云音乐精彩评论](https://mp.weixin.qq.com/s/tMVu8dUepSPIvm3yCMUt1g)》
- 爬取动态渲染页面(使用 ajax 加载数据)
- 爬取网易云音乐部分歌曲的精彩评论

3. 『[爬取网易云音乐单首歌曲的所有评论](./NeteaseMusic2)』

- 详细用法可以阅读《 [爬取《Five Hundred Miles》在网易云音乐的所有评论](https://mp.weixin.qq.com/s/kcA-6WEHWQ-DOwxtWtYjWw)》
- 使用 Selenium 爬取动态渲染页面(使用 ajax 加载数据)
- 存储数据到 MongoDB 
- 使用 Selenium 爬取《Five Hundred Miles》 在网易云音乐的所有评论, 然后存储到 MongoDB 中。


4. 『[多线程爬取 unsplash 图库](./UnsplashCrawler)』
- 详细用法可以阅读《[多线程爬取 unsplash 图库](https://mp.weixin.qq.com/s/hZxAAVW2UntRC8hyD_UWAA)》
- 使用 requests、urllib 等网络请求库。
- 使用多线程爬取网站


5.『[100行代码爬取全国所有必胜客餐厅信息](./Pizzahut)』
- 详细用法可以阅读《[100行代码爬取全国所有必胜客餐厅信息](https://mp.weixin.qq.com/s/ofBYdB26h4DJFyleZnBt5A)》
- 反爬虫分析


### 写在最后
该仓库会持续更新...

如果在您使用过程中遇到问题，可以到我的微信公众号『极客猴』留言。